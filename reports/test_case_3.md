### 🧪 Test Case 3

##### 🧾 Input Prompt
```text
What is 2 + 2?
```
##### ✅ Expected Answer
```text
4
```
##### 🤖 AI-generated Answer
```text
4
```
##### 📘 Source of Truth
```text
# Input Prompt:
What is 2 + 2?

---

# Expected Answer:
4
```
##### 🔍 AI-inferred Truth
```text
# Input Prompt:
What is 2 + 2?

---

# AI-generated Answer:
4
```
### 📊 Evaluation Metrics

##### AnswerRelevancy
- **Score:** 1.00
- **Reason:** The score is 1.00 because the answer provided a direct and accurate response to the input question with no irrelevant information.

##### ContextualPrecision
- **Score:** 1.00
- **Reason:** The score is 1.00 because all relevant nodes, like the first node which directly states '4', are ranked highest with no irrelevant nodes present. Perfect alignment!

##### ContextualRecall
- **Score:** 1.00
- **Reason:** The score is 1.00 because the expected output '4' is perfectly supported by the retrieval context, with no unsupportive reasons present. Great job!

##### ContextualRelevancy
- **Score:** 1.00
- **Reason:** The score is 1.00 because the retrieval context directly and accurately provides the answer '4' to the question 'What is 2 + 2?', demonstrating perfect relevance and precision.

##### Hallucination
- **Score:** 0.00
- **Reason:** The score is 0.00 because the actual output perfectly aligns with the provided context, with no contradictions present.

